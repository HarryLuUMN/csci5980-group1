{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "meaningful-cliff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Create output directories\n",
    "def create_output_dirs():\n",
    "    output_dirs = {\n",
    "        'base': 'output',\n",
    "        'models': 'output/models',\n",
    "        'metrics': 'output/metrics',\n",
    "        'plots': 'output/plots'\n",
    "    }\n",
    "    \n",
    "    for dir_path in output_dirs.values():\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "    \n",
    "    return output_dirs\n",
    "\n",
    "# Metrics tracking class\n",
    "class MetricsTracker:\n",
    "    def __init__(self, output_dirs):\n",
    "        self.output_dirs = output_dirs\n",
    "        self.history = {\n",
    "            'epoch': [],\n",
    "            'train_loss': [], 'val_loss': [],\n",
    "            'train_auc': [], 'val_auc': [],\n",
    "            'train_acc': [], 'val_acc': [],\n",
    "            'train_precision': [], 'val_precision': [],\n",
    "            'train_recall': [], 'val_recall': [],\n",
    "            'train_f1': [], 'val_f1': []\n",
    "        }\n",
    "        \n",
    "    def update(self, epoch, metrics):\n",
    "        self.history['epoch'].append(epoch)\n",
    "        for key, value in metrics.items():\n",
    "            self.history[key].append(value)\n",
    "    \n",
    "    def save_metrics(self):\n",
    "        # Save as CSV\n",
    "        df = pd.DataFrame(self.history)\n",
    "        df.to_csv(f\"{self.output_dirs['metrics']}/training_history.csv\", index=False)\n",
    "        \n",
    "        # Save as JSON\n",
    "        with open(f\"{self.output_dirs['metrics']}/training_history.json\", 'w') as f:\n",
    "            json.dump(self.history, f, indent=4)\n",
    "    \n",
    "    def plot_metrics(self):\n",
    "        # Plot loss curves\n",
    "        self._plot_metric('loss', 'Model Loss')\n",
    "        \n",
    "        # Plot AUC curves\n",
    "        self._plot_metric('auc', 'Model AUC')\n",
    "        \n",
    "        # Plot accuracy curves\n",
    "        self._plot_metric('acc', 'Model Accuracy')\n",
    "        \n",
    "        # Plot precision-recall curves\n",
    "        self._plot_metric('precision', 'Model Precision')\n",
    "        self._plot_metric('recall', 'Model Recall')\n",
    "        \n",
    "        plt.close('all')\n",
    "    \n",
    "    def _plot_metric(self, metric_name, title):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(self.history['epoch'], self.history[f'train_{metric_name}'], label=f'Train {metric_name}')\n",
    "        plt.plot(self.history['epoch'], self.history[f'val_{metric_name}'], label=f'Val {metric_name}')\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(metric_name.capitalize())\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(f\"{self.output_dirs['plots']}/{metric_name}_curves.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def plot_confusion_matrix(self, y_true, y_pred, phase='val'):\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f'Confusion Matrix - {phase.capitalize()} Set')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.savefig(f\"{self.output_dirs['plots']}/confusion_matrix_{phase}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def plot_roc_curve(self, fpr, tpr, auc, phase='val'):\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, label=f'ROC curve (AUC = {auc:.3f})')\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'ROC Curve - {phase.capitalize()} Set')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.savefig(f\"{self.output_dirs['plots']}/roc_curve_{phase}.png\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-finding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15: 100%|██████████| 6071/6071 [17:11<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15:\n",
      "Train - Loss: 0.2947, AUC: 0.8407, Acc: 0.8787, F1: 0.7791\n",
      "Val - Loss: 0.2561, AUC: 0.8800, Acc: 0.8908, F1: 0.8174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15: 100%|██████████| 6071/6071 [17:21<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15:\n",
      "Train - Loss: 0.2521, AUC: 0.8679, Acc: 0.8983, F1: 0.8167\n",
      "Val - Loss: 0.2363, AUC: 0.8724, Acc: 0.9029, F1: 0.8251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/15: 100%|██████████| 6071/6071 [17:25<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15:\n",
      "Train - Loss: 0.2331, AUC: 0.8785, Acc: 0.9068, F1: 0.8322\n",
      "Val - Loss: 0.2301, AUC: 0.8723, Acc: 0.9052, F1: 0.8275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/15: 100%|██████████| 6071/6071 [17:24<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15:\n",
      "Train - Loss: 0.2179, AUC: 0.8886, Acc: 0.9140, F1: 0.8458\n",
      "Val - Loss: 0.2257, AUC: 0.8742, Acc: 0.9080, F1: 0.8317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/15: 100%|██████████| 6071/6071 [17:24<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15:\n",
      "Train - Loss: 0.2045, AUC: 0.8951, Acc: 0.9190, F1: 0.8549\n",
      "Val - Loss: 0.2339, AUC: 0.8671, Acc: 0.9059, F1: 0.8251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/15: 100%|██████████| 6071/6071 [17:22<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15:\n",
      "Train - Loss: 0.1899, AUC: 0.9021, Acc: 0.9246, F1: 0.8650\n",
      "Val - Loss: 0.2120, AUC: 0.8932, Acc: 0.9132, F1: 0.8480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/15: 100%|██████████| 6071/6071 [17:23<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15:\n",
      "Train - Loss: 0.1746, AUC: 0.9121, Acc: 0.9319, F1: 0.8784\n",
      "Val - Loss: 0.2246, AUC: 0.8791, Acc: 0.9110, F1: 0.8380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/15:  35%|███▌      | 2150/6071 [06:09<11:13,  5.82it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, precision_recall_curve, accuracy_score, precision_score, recall_score, f1_score\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_output_dirs():\n",
    "    output_dirs = {\n",
    "        'base': 'output',\n",
    "        'models': 'output/models',\n",
    "        'metrics': 'output/metrics',\n",
    "        'plots': 'output/plots'\n",
    "    }\n",
    "    for dir_path in output_dirs.values():\n",
    "        os.makedirs(dir_path, exist_ok=True)\n",
    "    return output_dirs\n",
    "\n",
    "class MetricsTracker:\n",
    "    def __init__(self, output_dirs):\n",
    "        self.output_dirs = output_dirs\n",
    "        self.history = {\n",
    "            'epoch': [],\n",
    "            'train_loss': [], 'val_loss': [],\n",
    "            'train_auc': [], 'val_auc': [],\n",
    "            'train_acc': [], 'val_acc': [],\n",
    "            'train_precision': [], 'val_precision': [],\n",
    "            'train_recall': [], 'val_recall': [],\n",
    "            'train_f1': [], 'val_f1': []\n",
    "        }\n",
    "    \n",
    "    def update(self, epoch, metrics):\n",
    "        self.history['epoch'].append(epoch)\n",
    "        for key, value in metrics.items():\n",
    "            self.history[key].append(value)\n",
    "    \n",
    "    def save_metrics(self):\n",
    "        df = pd.DataFrame(self.history)\n",
    "        df.to_csv(f\"{self.output_dirs['metrics']}/training_history.csv\", index=False)\n",
    "        with open(f\"{self.output_dirs['metrics']}/training_history.json\", 'w') as f:\n",
    "            json.dump(self.history, f, indent=4)\n",
    "    \n",
    "    def plot_metrics(self):\n",
    "        metrics = ['loss', 'auc', 'acc', 'precision', 'recall']\n",
    "        for metric in metrics:\n",
    "            self._plot_metric(metric, f'Model {metric.upper()}')\n",
    "    \n",
    "    def _plot_metric(self, metric_name, title):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(self.history['epoch'], self.history[f'train_{metric_name}'], label=f'Train {metric_name}')\n",
    "        plt.plot(self.history['epoch'], self.history[f'val_{metric_name}'], label=f'Val {metric_name}')\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(metric_name.capitalize())\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.savefig(f\"{self.output_dirs['plots']}/{metric_name}_curves.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def plot_confusion_matrix(self, y_true, y_pred, phase='val'):\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f'Confusion Matrix - {phase.capitalize()} Set')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.savefig(f\"{self.output_dirs['plots']}/confusion_matrix_{phase}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    def plot_roc_curve(self, fpr, tpr, auc, phase='val'):\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, label=f'ROC curve (AUC = {auc:.3f})')\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'ROC Curve - {phase.capitalize()} Set')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.savefig(f\"{self.output_dirs['plots']}/roc_curve_{phase}.png\")\n",
    "        plt.close()\n",
    "\n",
    "class BreastHistopathologyDataset(Dataset):\n",
    "    def __init__(self, root_dir, split='train', transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.split = split\n",
    "        \n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for patient_dir in glob.glob(os.path.join(root_dir, \"*/\")):\n",
    "            for label in [0, 1]:\n",
    "                class_dir = os.path.join(patient_dir, str(label))\n",
    "                if not os.path.exists(class_dir):\n",
    "                    continue\n",
    "                paths = glob.glob(os.path.join(class_dir, \"*.png\"))\n",
    "                self.image_paths.extend(paths)\n",
    "                self.labels.extend([label] * len(paths))\n",
    "        \n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "            self.image_paths, self.labels, \n",
    "            test_size=0.3, \n",
    "            random_state=42\n",
    "        )\n",
    "        X_val, X_test, y_val, y_test = train_test_split(\n",
    "            X_temp, y_temp, \n",
    "            test_size=0.5, \n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        if split == 'train':\n",
    "            self.image_paths, self.labels = X_train, y_train\n",
    "        elif split == 'val':\n",
    "            self.image_paths, self.labels = X_val, y_val\n",
    "        else:\n",
    "            self.image_paths, self.labels = X_test, y_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "class ViTForHistopathology(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.vit = vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1)\n",
    "        self.vit.heads = nn.Linear(self.vit.hidden_dim, num_classes)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.vit(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=10, device='cuda'):\n",
    "    output_dirs = create_output_dirs()\n",
    "    metrics_tracker = MetricsTracker(output_dirs)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
    "    \n",
    "    best_val_auc = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_preds = []\n",
    "        train_labels = []\n",
    "        \n",
    "        for images, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            probs = torch.softmax(outputs, dim=1)[:, 1].detach().cpu().numpy()\n",
    "            preds = (probs > 0.5).astype(int)\n",
    "            train_preds.extend(preds)\n",
    "            train_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        train_metrics = {\n",
    "            'train_loss': train_loss / len(train_loader),\n",
    "            'train_auc': roc_auc_score(train_labels, train_preds),\n",
    "            'train_acc': accuracy_score(train_labels, train_preds),\n",
    "            'train_precision': precision_score(train_labels, train_preds),\n",
    "            'train_recall': recall_score(train_labels, train_preds),\n",
    "            'train_f1': f1_score(train_labels, train_preds)\n",
    "        }\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                probs = torch.softmax(outputs, dim=1)[:, 1].detach().cpu().numpy()\n",
    "                preds = (probs > 0.5).astype(int)\n",
    "                val_preds.extend(preds)\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_metrics = {\n",
    "            'val_loss': val_loss / len(val_loader),\n",
    "            'val_auc': roc_auc_score(val_labels, val_preds),\n",
    "            'val_acc': accuracy_score(val_labels, val_preds),\n",
    "            'val_precision': precision_score(val_labels, val_preds),\n",
    "            'val_recall': recall_score(val_labels, val_preds),\n",
    "            'val_f1': f1_score(val_labels, val_preds)\n",
    "        }\n",
    "        \n",
    "        metrics = {**train_metrics, **val_metrics}\n",
    "        metrics_tracker.update(epoch, metrics)\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            fpr, tpr, _ = roc_curve(val_labels, val_preds)\n",
    "            metrics_tracker.plot_roc_curve(fpr, tpr, val_metrics['val_auc'])\n",
    "            metrics_tracker.plot_confusion_matrix(val_labels, val_preds)\n",
    "        \n",
    "        if val_metrics['val_auc'] > best_val_auc:\n",
    "            best_val_auc = val_metrics['val_auc']\n",
    "            torch.save(model.state_dict(), f\"{output_dirs['models']}/ViT_best.pt\")\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "        print(f\"Train - Loss: {metrics['train_loss']:.4f}, AUC: {metrics['train_auc']:.4f}, \"\n",
    "              f\"Acc: {metrics['train_acc']:.4f}, F1: {metrics['train_f1']:.4f}\")\n",
    "        print(f\"Val - Loss: {metrics['val_loss']:.4f}, AUC: {metrics['val_auc']:.4f}, \"\n",
    "              f\"Acc: {metrics['val_acc']:.4f}, F1: {metrics['val_f1']:.4f}\")\n",
    "    \n",
    "    metrics_tracker.save_metrics()\n",
    "    metrics_tracker.plot_metrics()\n",
    "    \n",
    "    return model, metrics_tracker\n",
    "\n",
    "def main():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    data_root = \"data\"\n",
    "    train_dataset = BreastHistopathologyDataset(data_root, 'train', transform)\n",
    "    val_dataset = BreastHistopathologyDataset(data_root, 'val', transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "    \n",
    "    model = ViTForHistopathology()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    model, metrics_tracker = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        num_epochs=15,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-utilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                       std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Set data root\n",
    "data_root = \"data\"  # Make sure this points to your data directory\n",
    "\n",
    "# Create test dataset and loader\n",
    "test_dataset = BreastHistopathologyDataset(data_root, 'test', transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=16)\n",
    "\n",
    "# Initialize model\n",
    "model = ViTForHistopathology(num_classes=2, pretrained=True)\n",
    "model = model.to(device)\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Test evaluation\n",
    "test_loss = 0\n",
    "test_preds = []\n",
    "test_labels = []\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc='Testing'):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        test_loss += loss.item()\n",
    "        probs = torch.softmax(outputs, dim=1)[:, 1].detach().cpu().numpy()\n",
    "        test_preds.extend(probs)\n",
    "        test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "test_auc = roc_auc_score(test_labels, test_preds)\n",
    "print(f'\\nTest Results:')\n",
    "print(f'Test Loss: {test_loss/len(test_loader):.4f}, Test AUC: {test_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-dubai",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSCI_ML4H",
   "language": "python",
   "name": "csci_ml4h"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
